{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 26 17:45:12 2019\n",
    "\n",
    "@author: HP\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first of all we need load data therefore we should clean unordered data\n",
    "#this function labels each data based on '#' - hash each hash has own features and labels\n",
    "\n",
    "def Load_Data_Function(filename):\n",
    "    data = pd.DataFrame(columns = ['L_stands','Values']) #loading data into dataframe\n",
    "    with open(filename) as txtFile: #opening files\n",
    "        for each, stand in enumerate(txtFile): #\n",
    "            L_stands, Values = stand.split('#')\n",
    "            Values = [float(V.strip()) for V in Values.split(';')]\n",
    "            data.loc[each] = [L_stands, Values]\n",
    "            each = each + 1\n",
    "    data.iloc[:,0] = data.iloc[:,0].astype(np.int)\n",
    "    return data           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATA + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Load_Data_Function('Train.txt')\n",
    "data_test = Load_Data_Function('Test.txt')\n",
    "data_cv = Load_Data_Function('Cross_Validation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def List_Function(data):\n",
    "    return np.array(data.values.tolist())\n",
    "\n",
    "def Values_Function(data):\n",
    "    return data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading features of each data to variables\n",
    "data_train_X = List_Function(data_train.iloc[:,1])\n",
    "data_test_X = List_Function(data_test.iloc[:,1])\n",
    "data_cv_X = List_Function(data_cv.iloc[:,1])\n",
    "\n",
    "#loading labels of each data to variables\n",
    "data_train_y = Values_Function(data_train.iloc[:,0])\n",
    "data_test_y = Values_Function(data_test.iloc[:,0])\n",
    "data_cv_y = Values_Function(data_cv.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as NT\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data 0.9673\n",
      "Accurracy: 96.73 %\n"
     ]
    }
   ],
   "source": [
    "MLP_CLF = NT(hidden_layer_sizes=(100,100,100), alpha=0.0001) \n",
    "MLP_CLF.fit(data_train_X, data_train_y) #finding coefficients \n",
    "#prediction \n",
    "y_pred = MLP_CLF.predict(data_test_X)\n",
    "#finding accurrracy percentage\n",
    "MLP_CLF_AC_1 = round(accuracy_score(data_test_y, y_pred),4)\n",
    "print('Evaluating through test_data', MLP_CLF_AC_1)\n",
    "print('Accurracy:', MLP_CLF_AC_1 * 100, '%')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#confusion matrix\n",
    "c_m = confusion_matrix(data_test_y, y_pred)\n",
    "print(c_m)\n",
    "#ploting\n",
    "sns.heatmap(c_m, center=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let just give several different hidden layer size and alphas\n",
    "H_l = [50,150,250]\n",
    "A = [0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this function choose best score through cross validation data\n",
    "#based on given hidden layer size and alphas\n",
    "def High_Score_Function_NT(hidden, a_v, X_tr, y_tr, X_cv, y_cv):      \n",
    "    _sc = 0\n",
    "    _hidden =[0] #empty\n",
    "    _a_v = [0] #empty\n",
    "    for i in hidden:\n",
    "        for j in a_v :\n",
    "            classifier = NT(hidden_layer_sizes=i, alpha=j)\n",
    "            classifier.fit(X_tr, y_tr) # findig coefficients \n",
    "            sc = classifier.score(X_cv, y_cv) #tuning paramaters\n",
    "            if sc > _sc: #choose high score\n",
    "                _hidden = i #best hidden layer size \n",
    "                _a_v = j #best alpha\n",
    "                _sc = sc  #best score\n",
    "            print('Hidden_layer_size =', i,'alpha =', j , 'Score =', sc)\n",
    "    return _hidden, _a_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden_layer_size = 50 alpha = 0.001 Score = 0.9792079207920792\n",
      "Hidden_layer_size = 50 alpha = 0.0001 Score = 0.9712871287128713\n",
      "Hidden_layer_size = 150 alpha = 0.001 Score = 0.9811881188118812\n",
      "Hidden_layer_size = 150 alpha = 0.0001 Score = 0.9811881188118812\n",
      "Hidden_layer_size = 250 alpha = 0.001 Score = 0.9871287128712871\n",
      "Hidden_layer_size = 250 alpha = 0.0001 Score = 0.9841584158415841\n"
     ]
    }
   ],
   "source": [
    "h_l, a_v = High_Score_Function_NT(H_l, A, data_train_X , data_train_y, data_cv_X, data_cv_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=250, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_CLF = NT(hidden_layer_sizes = h_l, alpha = a_v) #best alpha and best hidden layer size\n",
    "MLP_CLF.fit(data_train_X, data_train_y) #finding coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data 0.9732\n",
      "Accurracy: 97.32 %\n"
     ]
    }
   ],
   "source": [
    "#finding accurrracy percentage \n",
    "MLP_CLF_AC_2 = round(MLP_CLF.score(data_test_X, data_test_y),4)\n",
    "print('Evaluating through test_data', MLP_CLF_AC_2)\n",
    "print('Accurracy:', MLP_CLF_AC_2 * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.9604\n",
      "Accurracy: 96.04 %\n"
     ]
    }
   ],
   "source": [
    "SVC_CLF = SVC(kernel = 'linear', random_state = 0)\n",
    "SVC_CLF.fit(data_train_X, data_train_y)\n",
    "# Predicting the Test set results\n",
    "y_pred = SVC_CLF.predict(data_test_X)\n",
    "#finding accurracy_score\n",
    "SVC_AC_1 = round(accuracy_score(data_test_y, y_pred),4)\n",
    "print('Evaluating through test_data:', SVC_AC_1)\n",
    "print('Accurracy:', SVC_AC_1 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC as SV\n",
    "#let just give several different penalty paramater C  \n",
    "C = [0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this function choose best score through cross validation data\n",
    "#based on given penalty paramaeter C\n",
    "def High_Score_Function_SVC(C, X_tr, y_tr, X_cv, y_cv):\n",
    "     _sc = 0\n",
    "     _C =[0]\n",
    "     for i in C:\n",
    "        classifier = SV(C=i)\n",
    "        classifier.fit(X_tr, y_tr)\n",
    "        sc = classifier.score(X_cv, y_cv) #tuning cross validation paramaters\n",
    "        if sc > _sc:\n",
    "            _C = i #finding best penalty parameter\n",
    "            _sc = sc\n",
    "        print('C =', i,'Score =', sc)\n",
    "     return _C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001 Score = 0.9217821782178218\n",
      "C = 0.01 Score = 0.906930693069307\n",
      "C = 0.1 Score = 0.8861386138613861\n",
      "C = 1 Score = 0.8712871287128713\n"
     ]
    }
   ],
   "source": [
    "_c = High_Score_Function_SVC(C, data_train_X , data_train_y, data_cv_X, data_cv_y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.893\n",
      "Accurracy: 89.3 %\n"
     ]
    }
   ],
   "source": [
    "SVC_CLF = SV(C =_c)\n",
    "SVC_CLF.fit(data_train_X, data_train_y) \n",
    "SVC_AC_2 = round(SVC_CLF.score(data_test_X, data_test_y),4)\n",
    "print('Evaluating through test_data:', SVC_AC_2)\n",
    "print('Accurracy:', SVC_AC_2 * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.7909\n",
      "Accurracy: 79.09 %\n"
     ]
    }
   ],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "DT_CLF = DT(criterion = 'entropy', random_state = 0)\n",
    "DT_CLF.fit(data_train_X, data_train_y)\n",
    "# Predicting the Test set results\n",
    "y_pred = DT_CLF.predict(data_test_X)\n",
    "#finding accurracy_score\n",
    "DT_AC_1 = round(accuracy_score(data_test_y, y_pred),4)\n",
    "print('Evaluating through test_data:', DT_AC_1)\n",
    "print('Accurracy:', DT_AC_1 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let just give several different max_depth and min_samples_split  \n",
    "max_d = [16, 28]\n",
    "min_s = [6, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this function choose best score through cross validation data\n",
    "#based on given different max_depth and min_samples_split \n",
    "def High_Score_Function_DT(max_d, min_s,  X_tr, y_tr, X_cv, y_cv):\n",
    "    _sc = 0\n",
    "    for i in max_d:\n",
    "        for j in min_s:\n",
    "            classifier = DT(max_depth=i, min_samples_split=j)\n",
    "            classifier.fit(X_tr, y_tr)\n",
    "            sc = classifier.score(X_cv, y_cv)\n",
    "            if sc > _sc:\n",
    "                _d = i \n",
    "                _s = j\n",
    "                _sc = sc\n",
    "                print('max_depth =',i,'min_samples =',j,'Score =',sc)\n",
    "    return _d, _s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 16 min_samples = 6 Score = 0.7564356435643564\n",
      "max_depth = 28 min_samples = 6 Score = 0.7752475247524753\n"
     ]
    }
   ],
   "source": [
    "_d, _s = High_Score_Function_DT(max_d, min_s, data_train_X , data_train_y, data_cv_X, data_cv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.7711\n",
      "Accurracy: 77.11 %\n"
     ]
    }
   ],
   "source": [
    "DT_CLF = DT(max_depth = _d, min_samples_split = _s)\n",
    "DT_CLF.fit(data_train_X, data_train_y) \n",
    "DT_AC_2 = round(DT_CLF.score(data_test_X, data_test_y),4)\n",
    "print('Evaluating through test_data:', DT_AC_2)\n",
    "print('Accurracy:', DT_AC_2 * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First step merging all data\n",
    "data_merged = data_train.append(data_cv, ignore_index = True).append(data_test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#after merging data now this function will devide data into 3 parts\n",
    "#60% for train, 20 % for test, and 20% for Cross validation\n",
    "#then finding accuracy\n",
    "\n",
    "def Average_Function(data, classifier):\n",
    "    m = len(data)\n",
    "    data_cv_sc = []\n",
    "    data_test_sc = []\n",
    "    \n",
    "    for each in range(10):\n",
    "        np.random.seed(each) #different random numbers into array\n",
    "        index = np.arange(m)\n",
    "        np.random.shuffle(index) #shuffle\n",
    "        t = int(0.6 * m) # 60% data will be for training\n",
    "        v = int(0.8 * m) # 20% for cross and 20 % for test\n",
    "        \n",
    "        train = index[:t]#60%\n",
    "        cv = index[t:v] #20% \n",
    "        test = index[v:] #20%\n",
    "        \n",
    "        #loading data \n",
    "        data_train = data.loc[train]\n",
    "        data_cv = data.loc[cv]\n",
    "        data_test = data.loc[test]\n",
    "        \n",
    "        #features and values\n",
    "        data_train_X = List_Function(data_train.iloc[:,1])\n",
    "        data_test_X = List_Function(data_test.iloc[:,1])\n",
    "        data_cv_X = List_Function(data_cv.iloc[:,1])\n",
    "        \n",
    "        #labels\n",
    "        data_train_y = Values_Function(data_train.iloc[:,0])\n",
    "        data_test_y = Values_Function(data_test.iloc[:,0])\n",
    "        data_cv_y = Values_Function(data_cv.iloc[:,0])\n",
    "        \n",
    "        #finding accuracy for evaluating average performance\n",
    "        classifier.fit(data_train_X, data_train_y)\n",
    "        data_cv_sc.append(classifier.score(data_cv_X, data_cv_y))\n",
    "        data_test_sc.append(classifier.score(data_test_X, data_test_y))\n",
    "    \n",
    "    return sum(data_cv_sc)/10, sum(data_test_sc)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR NEURAL NETWORKS + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 0.9742942050520058  Test score: 0.9730064388311044\n",
      "Cross Validation accuracy: 97.4294 %  Test accuracy: 97.3006 %\n"
     ]
    }
   ],
   "source": [
    "average_cv_sc_MLP, average_test_sc_MLP = Average_Function(data_merged, MLP_CLF)\n",
    "print('Cross Validation score:' , average_cv_sc_MLP, ' Test score:', average_test_sc_MLP )\n",
    "print('Cross Validation accuracy:' , round(average_cv_sc_MLP * 100,4),'%', ' Test accuracy:', round(average_test_sc_MLP * 100,4),'%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR SVM +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 0.9011887072808322  Test score: 0.9034670629024271\n",
      "Cross Validation accuracy: 90.1189 %  Test accuracy: 90.3467 %\n"
     ]
    }
   ],
   "source": [
    "average_cv_sc_SVC, average_test_sc_SVC = Average_Function(data_merged, SVC_CLF)\n",
    "print('Cross Validation score:' , average_cv_sc_SVC, ' Test score:', average_test_sc_SVC )\n",
    "print('Cross Validation accuracy:' , round(average_cv_sc_SVC * 100,4),'%', ' Test accuracy:', round(average_test_sc_SVC * 100,4),'%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR DECISION TREE +  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 0.7512630014858841  Test score: 0.7478454680534918\n",
      "Cross Validation accuracy: 75.1263 %  Test acurracy: 74.7845 %\n"
     ]
    }
   ],
   "source": [
    "average_cv_sc_DT, average_test_sc_DT = Average_Function(data_merged, DT_CLF)\n",
    "print('Cross Validation score:' , average_cv_sc_DT, ' Test score:', average_test_sc_DT )\n",
    "print('Cross Validation accuracy:' , round(average_cv_sc_DT * 100,4),'%', ' Test acurracy:', round(average_test_sc_DT * 100,4),'%' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
