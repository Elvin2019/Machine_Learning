{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 26 17:45:12 2019\n",
    "\n",
    "@author: HP\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first of all we need load data therefore we should clean unordered data\n",
    "#this function labels each data based on '#' - hash each hash has own features and labels\n",
    "\n",
    "def Load_Data_Function(filename):\n",
    "    data = pd.DataFrame(columns = ['L_stands','Values']) #loading data into dataframe\n",
    "    with open(filename) as txtFile: #opening files\n",
    "        for each, stand in enumerate(txtFile): #\n",
    "            L_stands, Values = stand.split('#')\n",
    "            Values = [float(V.strip()) for V in Values.split(';')]\n",
    "            data.loc[each] = [L_stands, Values]\n",
    "            each = each + 1\n",
    "    data.iloc[:,0] = data.iloc[:,0].astype(np.int)\n",
    "    return data           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA + \n",
    "data_train = Load_Data_Function('Train.txt')\n",
    "data_test = Load_Data_Function('Test.txt')\n",
    "data_cv = Load_Data_Function('Cross_Validation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def List_Function(data):\n",
    "    return np.array(data.values.tolist())\n",
    "\n",
    "def Values_Function(data):\n",
    "    return data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading features of each data to variables\n",
    "data_train_X = List_Function(data_train.iloc[:,1])\n",
    "data_test_X = List_Function(data_test.iloc[:,1])\n",
    "data_cv_X = List_Function(data_cv.iloc[:,1])\n",
    "\n",
    "#loading labels of each data to variables\n",
    "data_train_y = Values_Function(data_train.iloc[:,0])\n",
    "data_test_y = Values_Function(data_test.iloc[:,0])\n",
    "data_cv_y = Values_Function(data_cv.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEURAL NETWORKS + \n",
    "from sklearn.neural_network import MLPClassifier as NT\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data 0.9713\n",
      "Accurracy: 97.13000000000001 %\n"
     ]
    }
   ],
   "source": [
    "MLP_CLF = NT(hidden_layer_sizes=(100,100,100), alpha=0.0001) \n",
    "MLP_CLF.fit(data_train_X, data_train_y) #finding coefficients \n",
    "#prediction \n",
    "y_pred = MLP_CLF.predict(data_test_X)\n",
    "#finding accurrracy percentage\n",
    "MLP_CLF_AC_1 = round(accuracy_score(data_test_y, y_pred),4)\n",
    "print('Evaluating through test_data', MLP_CLF_AC_1)\n",
    "print('Accurracy:', MLP_CLF_AC_1 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 46  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  1  0  0]\n",
      " [ 0  0  1 37  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 34  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 51  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 48  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0 39  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 43  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0 36  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0 35  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 49  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0 49  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 38  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 35  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 39  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  0 35  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 37  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a900928320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "c_m = confusion_matrix(data_test_y, y_pred)\n",
    "print(c_m)\n",
    "#ploting\n",
    "sns.heatmap(c_m, center=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let just give several different hidden layer size and alphas\n",
    "H_l = [50,150,250]\n",
    "A = [0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function choose best score through cross validation data\n",
    "#based on given hidden layer size and alphas\n",
    "def High_Score_Function_NT(hidden, a_v, X_tr, y_tr, X_cv, y_cv):      \n",
    "    _sc = 0\n",
    "    _hidden =[0] #empty\n",
    "    _a_v = [0] #empty\n",
    "    for i in hidden:\n",
    "        for j in a_v :\n",
    "            classifier = NT(hidden_layer_sizes=i, alpha=j)\n",
    "            classifier.fit(X_tr, y_tr) # findig coefficients \n",
    "            sc = classifier.score(X_cv, y_cv) #tuning paramaters\n",
    "            if sc > _sc: #choose high score\n",
    "                _hidden = i #best hidden layer size \n",
    "                _a_v = j #best alpha\n",
    "                _sc = sc  #best score\n",
    "            print('Hidden_layer_size =', i,'alpha =', j , 'Score =', sc)\n",
    "    return _hidden, _a_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden_layer_size = 50 alpha = 0.001 Score = 0.9712871287128713\n",
      "Hidden_layer_size = 50 alpha = 0.0001 Score = 0.9742574257425742\n",
      "Hidden_layer_size = 150 alpha = 0.001 Score = 0.9821782178217822\n",
      "Hidden_layer_size = 150 alpha = 0.0001 Score = 0.9841584158415841\n",
      "Hidden_layer_size = 250 alpha = 0.001 Score = 0.9851485148514851\n",
      "Hidden_layer_size = 250 alpha = 0.0001 Score = 0.9831683168316832\n"
     ]
    }
   ],
   "source": [
    "h_l, a_v = High_Score_Function_NT(H_l, A, data_train_X , data_train_y, data_cv_X, data_cv_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=250, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_CLF = NT(hidden_layer_sizes = h_l, alpha = a_v) #best alpha and best hidden layer size\n",
    "MLP_CLF.fit(data_train_X, data_train_y) #finding coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data 0.9742\n",
      "Accurracy: 97.42 %\n"
     ]
    }
   ],
   "source": [
    "#finding accurrracy percentage \n",
    "MLP_CLF_AC_2 = round(MLP_CLF.score(data_test_X, data_test_y),4)\n",
    "print('Evaluating through test_data', MLP_CLF_AC_2)\n",
    "print('Accurracy:', MLP_CLF_AC_2 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines (SVM) + \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.9604\n",
      "Accurracy: 96.04 %\n"
     ]
    }
   ],
   "source": [
    "SVC_CLF = SVC(kernel = 'linear', random_state = 0)\n",
    "SVC_CLF.fit(data_train_X, data_train_y)\n",
    "# Predicting the Test set results\n",
    "y_pred = SVC_CLF.predict(data_test_X)\n",
    "#finding accurracy_score\n",
    "SVC_AC_1 = round(accuracy_score(data_test_y, y_pred),4)\n",
    "print('Evaluating through test_data:', SVC_AC_1)\n",
    "print('Accurracy:', SVC_AC_1 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC as SV\n",
    "#let just give several different penalty paramater C  \n",
    "C = [0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function choose best score through cross validation data\n",
    "#based on given penalty paramaeter C\n",
    "def High_Score_Function_SVC(C, X_tr, y_tr, X_cv, y_cv):\n",
    "     _sc = 0\n",
    "     _C =[0]\n",
    "     for i in C:\n",
    "        classifier = SV(C=i)\n",
    "        classifier.fit(X_tr, y_tr)\n",
    "        sc = classifier.score(X_cv, y_cv) #tuning cross validation paramaters\n",
    "        if sc > _sc:\n",
    "            _C = i #finding best penalty parameter\n",
    "            _sc = sc\n",
    "        print('C =', i,'Score =', sc)\n",
    "     return _C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001 Score = 0.9217821782178218\n",
      "C = 0.01 Score = 0.903960396039604\n",
      "C = 0.1 Score = 0.8752475247524752\n",
      "C = 1 Score = 0.8801980198019802\n"
     ]
    }
   ],
   "source": [
    "_c = High_Score_Function_SVC(C, data_train_X , data_train_y, data_cv_X, data_cv_y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.893\n",
      "Accurracy: 89.3 %\n"
     ]
    }
   ],
   "source": [
    "SVC_CLF = SV(C =_c)\n",
    "SVC_CLF.fit(data_train_X, data_train_y) \n",
    "SVC_AC_2 = round(SVC_CLF.score(data_test_X, data_test_y),4)\n",
    "print('Evaluating through test_data:', SVC_AC_2)\n",
    "print('Accurracy:', SVC_AC_2 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE +\n",
    "from sklearn.tree import DecisionTreeClassifier as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.7909\n",
      "Accurracy: 79.09 %\n"
     ]
    }
   ],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "DT_CLF = DT(criterion = 'entropy', random_state = 0)\n",
    "DT_CLF.fit(data_train_X, data_train_y)\n",
    "# Predicting the Test set results\n",
    "y_pred = DT_CLF.predict(data_test_X)\n",
    "#finding accurracy_score\n",
    "DT_AC_1 = round(accuracy_score(data_test_y, y_pred),4)\n",
    "print('Evaluating through test_data:', DT_AC_1)\n",
    "print('Accurracy:', DT_AC_1 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let just give several different max_depth and min_samples_split  \n",
    "max_d = [16, 28]\n",
    "min_s = [6, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function choose best score through cross validation data\n",
    "#based on given different max_depth and min_samples_split \n",
    "def High_Score_Function_DT(max_d, min_s,  X_tr, y_tr, X_cv, y_cv):\n",
    "    _sc = 0\n",
    "    for i in max_d:\n",
    "        for j in min_s:\n",
    "            classifier = DT(max_depth=i, min_samples_split=j)\n",
    "            classifier.fit(X_tr, y_tr)\n",
    "            sc = classifier.score(X_cv, y_cv)\n",
    "            if sc > _sc:\n",
    "                _d = i \n",
    "                _s = j\n",
    "                _sc = sc\n",
    "                print('max_depth =',i,'min_samples =',j,'Score =',sc)\n",
    "    return _d, _s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 16 min_samples = 6 Score = 0.7633663366336634\n",
      "max_depth = 28 min_samples = 6 Score = 0.7712871287128713\n"
     ]
    }
   ],
   "source": [
    "_d, _s = High_Score_Function_DT(max_d, min_s, data_train_X , data_train_y, data_cv_X, data_cv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating through test_data: 0.7611\n",
      "Accurracy: 76.11 %\n"
     ]
    }
   ],
   "source": [
    "DT_CLF = DT(max_depth = _d, min_samples_split = _s)\n",
    "DT_CLF.fit(data_train_X, data_train_y) \n",
    "DT_AC_2 = round(DT_CLF.score(data_test_X, data_test_y),4)\n",
    "print('Evaluating through test_data:', DT_AC_2)\n",
    "print('Accurracy:', DT_AC_2 * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRA \n",
    "#First step merging all data\n",
    "data_merged = data_train.append(data_cv, ignore_index = True).append(data_test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after merging data now this function will devide data into 3 parts\n",
    "#60% for train, 20 % for test, and 20% for Cross validation\n",
    "#then finding accuracy\n",
    "\n",
    "def Average_Function(data, classifier):\n",
    "    m = len(data)\n",
    "    data_cv_sc = []\n",
    "    data_test_sc = []\n",
    "    \n",
    "    for each in range(10):\n",
    "        np.random.seed(each) #different random numbers into array\n",
    "        index = np.arange(m)\n",
    "        np.random.shuffle(index) #shuffle\n",
    "        t = int(0.6 * m) # 60% data will be for training\n",
    "        v = int(0.8 * m) # 20% for cross and 20 % for test\n",
    "        \n",
    "        train = index[:t]#60%\n",
    "        cv = index[t:v] #20% \n",
    "        test = index[v:] #20%\n",
    "        \n",
    "        #loading data \n",
    "        data_train = data.loc[train]\n",
    "        data_cv = data.loc[cv]\n",
    "        data_test = data.loc[test]\n",
    "        \n",
    "        #features and values\n",
    "        data_train_X = List_Function(data_train.iloc[:,1])\n",
    "        data_test_X = List_Function(data_test.iloc[:,1])\n",
    "        data_cv_X = List_Function(data_cv.iloc[:,1])\n",
    "        \n",
    "        #labels\n",
    "        data_train_y = Values_Function(data_train.iloc[:,0])\n",
    "        data_test_y = Values_Function(data_test.iloc[:,0])\n",
    "        data_cv_y = Values_Function(data_cv.iloc[:,0])\n",
    "        \n",
    "        #finding accuracy for evaluating average performance\n",
    "        classifier.fit(data_train_X, data_train_y)\n",
    "        data_cv_sc.append(classifier.score(data_cv_X, data_cv_y))\n",
    "        data_test_sc.append(classifier.score(data_test_X, data_test_y))\n",
    "    \n",
    "    return sum(data_cv_sc)/10, sum(data_test_sc)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 0.9742942050520058  Test score: 0.9730064388311044\n",
      "Cross Validation accuracy: 97.4294 %  Test sacuracy: 97.3006 %\n"
     ]
    }
   ],
   "source": [
    "#FOR NEURAL NETWORKS + \n",
    "average_cv_sc_MLP, average_test_sc_MLP = Average_Function(data_merged, MLP_CLF)\n",
    "print('Cross Validation score:' , average_cv_sc_MLP, ' Test score:', average_test_sc_MLP )\n",
    "print('Cross Validation accuracy:' , round(average_cv_sc_MLP * 100,4),'%', ' Test sacuracy:', round(average_test_sc_MLP * 100,4),'%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 0.9011887072808322  Test score: 0.9034670629024271\n",
      "Cross Validation accuracy: 90.1189 %  Test sacuracy: 90.3467 %\n"
     ]
    }
   ],
   "source": [
    "#FOR SVM +\n",
    "average_cv_sc_SVC, average_test_sc_SVC = Average_Function(data_merged, SVC_CLF)\n",
    "print('Cross Validation score:' , average_cv_sc_SVC, ' Test score:', average_test_sc_SVC )\n",
    "print('Cross Validation accuracy:' , round(average_cv_sc_SVC * 100,4),'%', ' Test accuracy:', round(average_test_sc_SVC * 100,4),'%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score: 0.7512630014858841  Test score: 0.7478454680534918\n",
      "Cross Validation accuracy: 75.1263 %  Test sacuracy: 74.7845 %\n"
     ]
    }
   ],
   "source": [
    "#FOR DECISION TREE +  \n",
    "average_cv_sc_DT, average_test_sc_DT = Average_Function(data_merged, DT_CLF)\n",
    "print('Cross Validation score:' , average_cv_sc_DT, ' Test score:', average_test_sc_DT )\n",
    "print('Cross Validation accuracy:' , round(average_cv_sc_DT * 100,4),'%', ' Test acurracy:', round(average_test_sc_DT * 100,4),'%' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
